# Optimization techniques for machine learning

This is an evolving repository where we aim at hosting several of our readings about optimization methods in machine learning and related codes. This new version will be updated progressively. Below are some of the materials to be covered:
 * Discrete optimizaton
 * Continous optimization: Direct methods, Iterative methods (Newtton-based methods, BGFS, Projeced gradient , etc)
 * Eign values problems and Algorithm: Jacobi method, QR, Power/Inverse Power method
 * Dynamic programmic for optimization (-- see Hamdi A. Taha, Operational Researc)

From now, the main references are :
 - Roger D. Peng, Advanced Statistical Computing, see https://bookdown.org/rdpeng/advstatcomp/general-optimization.html
 -  Robert Gray, Advanced Statistical Computing, Lectures Notes, see https://pages.stat.wisc.edu/~mchung/teaching/stat471/stat_computing.pdf
 -  etc.
 
